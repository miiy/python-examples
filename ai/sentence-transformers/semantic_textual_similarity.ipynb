{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Semantic Textual Similarity 语义文本相似性\n",
    "\n",
    "一旦计算了句子嵌入，通常需要将它们相互比较。在这里，我向您展示如何计算嵌入之间的余弦相似性，例如，测量两个文本的语义相似性。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d892c919bd99e7f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
      "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
      "        [-0.1004, -0.0774, -0.0014,  ..., -0.0010,  0.0718,  0.0221]])\n",
      "tensor([[ 0.0163, -0.0700,  0.0384,  ...,  0.0447,  0.0254, -0.0023],\n",
      "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
      "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389]])\n",
      "\n",
      "tensor([[ 0.2838,  0.1310, -0.0029],\n",
      "        [ 0.2277, -0.0327, -0.0136],\n",
      "        [ 0.0543, -0.0502,  0.8939]])\n",
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "              'A man is playing guitar',\n",
    "              'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(embeddings1)\n",
    "print(embeddings2)\n",
    "print()\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "print(cosine_scores)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T03:02:33.702235Z",
     "start_time": "2024-01-04T03:02:33.442389Z"
    }
   },
   "id": "883913a978292e3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "convert_to_tensor=True 返回一个包含我们的嵌入的 pytorch 张量。\n",
    "\n",
    "util.cos_sim 它计算A中所有向量和B中所有向量之间的余弦相似性。\n",
    "\n",
    "在上面的例子中，它返回具有嵌入1和嵌入2之间的所有可能对的相应余弦相似性得分的3x3矩阵。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a089f77c742e316c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1310]])\n",
      "tensor([[0.2277]])\n"
     ]
    }
   ],
   "source": [
    "cosine_scores = util.cos_sim(embeddings1[0], embeddings2[1])\n",
    "print(cosine_scores)\n",
    "cosine_scores = util.cos_sim(embeddings1[1], embeddings2[0])\n",
    "print(cosine_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T03:09:48.572982Z",
     "start_time": "2024-01-04T03:09:48.556978Z"
    }
   },
   "id": "9566534739938a30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "您也可以使用此函数来找出余弦相似度得分最高的对："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54e96f84506319e8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6788\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5096\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2560\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2440\n",
      "A man is playing guitar \t\t The cat plays in the garden \t\t Score: 0.2105\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1969\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1692\n",
      "The cat sits outside \t\t A woman watches TV \t\t Score: 0.1310\n",
      "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0900\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Single list of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "#Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T03:15:57.166523Z",
     "start_time": "2024-01-04T03:15:55.941348Z"
    }
   },
   "id": "c0baf814c6d0e362"
  },
  {
   "cell_type": "markdown",
   "source": [
    "在上面的方法中，我们使用蛮力方法来找到得分最高的对，这具有二次复杂度。对于一长串的句子来说，这可能是不可行的。如果你想在一长串句子中找到得分最高的句子对，可以看看短语挖掘。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1611375a5320d93b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

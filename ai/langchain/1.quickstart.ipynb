{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "\n",
    "<https://python.langchain.com/docs/get_started/quickstart>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc8154805c747a7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install \"langserve[all]\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8033148e5e096f80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 设置环境变量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de16ed5aa898c1d7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'sk-...'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]= \"sk-...\"\n",
    "os.environ[\"HTTPS_PROXY\"]= \"http://127.0.0.1:7890\"\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:14.801623Z",
     "start_time": "2023-12-26T09:58:14.784065Z"
    }
   },
   "id": "ca1a9fd62aab5314"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building with LangChain\n",
    "\n",
    "LangChain提供了许多可用于构建语言模型应用程序的模块。\n",
    "\n",
    "最简单、最常见的链包含：\n",
    "\n",
    "LLM/Chat Model: 语言模型是这里的核心推理引擎。\n",
    "\n",
    "Prompt Template: 为语言模型提供指令。\n",
    "\n",
    "Output Parser: 将来自语言模型的原始响应转换为更可用的格式。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d9b54282b56be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LLM / Chat Model\n",
    "\n",
    "有两种语言模型：\n",
    "\n",
    "- LLM: 底层模型将字符串作为输入并返回字符串\n",
    "\n",
    "- ChatModel: 底层模型将消息列表作为输入并返回消息\n",
    "\n",
    "基本消息由 BaseMessage 定义\n",
    "\n",
    "- content: 消息的内容\n",
    "- role: BaseMessage 所来自的实体。\n",
    "\n",
    "LangChain提供了几个对象来方便区分不同的角色：\n",
    "\n",
    "- HumanMessage\n",
    "- AIMessage\n",
    "- SystemMessage\n",
    "- FunctionMessage/ToolMessage\n",
    "\n",
    "使用 .invoke() 调用 LLM 或 ChatModel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a770250cf360b1b5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Colorful Feet Co.\n"
     ]
    },
    {
     "data": {
      "text/plain": "AIMessage(content='ColorfulStep')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "print(llm.invoke(text))\n",
    "\n",
    "chat_model.invoke(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:33:18.956730Z",
     "start_time": "2023-12-26T09:33:16.297882Z"
    }
   },
   "id": "1e1d21fa8bac826a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt templates 提示词模版"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36ca54cd5ae41af"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'What is a good name for a company that makes colorful socks?'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product='colorful socks')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:27:18.085284Z",
     "start_time": "2023-12-26T09:27:18.067694Z"
    }
   },
   "id": "2b9e70cced478709"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[SystemMessage(content='You are a helpful assistant that translates English to French.'),\n HumanMessage(content='I love programming.')]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),                     \n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:30:44.928976Z",
     "start_time": "2023-12-26T09:30:44.872261Z"
    }
   },
   "id": "6f1b7698c113b00b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output parsers 输出解析器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acb41b0a45dbb144"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['hi', 'bye']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:32:50.336765Z",
     "start_time": "2023-12-26T09:32:50.289445Z"
    }
   },
   "id": "515dc3d1ce8860e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composing with LCEL 用 LCEL 组合\n",
    "\n",
    "现在可以将所有这些组合成一条链。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ee9da5c49cef7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['red', 'blue', 'green', 'yellow', 'purple']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "    \n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),                     \n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})\n",
    "\n",
    "# 使用 | 语法将这些组件连接在一起。| 语法由 LangChain 表达式语言（LCEL）提供支持"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:38:02.311114Z",
     "start_time": "2023-12-26T09:38:00.535043Z"
    }
   },
   "id": "e8c6a884ee33021e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Serving with LangServe 使用 LangServe 提供服务"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1d0d0ea7da09345"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting fastapi\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/e4/f57e0eb823ead5bdf80e00d484e86925b2d2d2df53428ddf85c3b0e0e718/fastapi-0.106.0-py3-none-any.whl (92 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.1/92.1 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting anyio<4.0.0,>=3.7.1 (from fastapi)\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl (80 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m80.9/80.9 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./venv/lib/python3.10/site-packages (from fastapi) (2.5.3)\r\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl (66 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.0/67.0 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from fastapi) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.14.6)\r\n",
      "Installing collected packages: anyio, starlette, fastapi\r\n",
      "  Attempting uninstall: anyio\r\n",
      "    Found existing installation: anyio 4.2.0\r\n",
      "    Uninstalling anyio-4.2.0:\r\n",
      "      Successfully uninstalled anyio-4.2.0\r\n",
      "Successfully installed anyio-3.7.1 fastapi-0.106.0 starlette-0.27.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:51:09.166249Z",
     "start_time": "2023-12-26T09:51:02.142924Z"
    }
   },
   "id": "a360e4ecd91381a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Playground\n",
    "\n",
    "```bash\n",
    "python 1.serve.py\n",
    "```\n",
    "\n",
    "<http://localhost:8000/category_chain/playground/>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3215879b4e9cb583"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Client"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ee5aecf13e478f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['red', 'blue', 'green', 'yellow', 'purple']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/category_chain/\")\n",
    "remote_chain.invoke({\"text\": \"colors\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T10:03:14.472623Z",
     "start_time": "2023-12-26T10:03:11.749632Z"
    }
   },
   "id": "aae6562c211c0ece"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51bca947695a9256"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

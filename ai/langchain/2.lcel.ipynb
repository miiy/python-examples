{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Get Started"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d28cf19d5de69d3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]= \"sk-...\"\n",
    "os.environ[\"HTTPS_PROXY\"]= \"http://127.0.0.1:7890\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-27T08:56:36.409626Z"
    }
   },
   "id": "32a37c405747989e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic example: prompt + model + output parser\n",
    "\n",
    "创建一个接受主体并生成笑话的链"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14e3e14cc9206462"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Why did the ice cream go to therapy?\\n\\nBecause it had too many toppings and couldn't handle the sprinkles!\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T11:33:05.578810Z",
     "start_time": "2023-12-26T11:33:02.583076Z"
    }
   },
   "id": "8ca3501f6eb37a2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| 符号类似于 unix 管道运算符，它将不同的组件链接在一起，将一个组件的输出作为下一个组件的输入。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeff6b13c51bbe1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.Prompt\n",
    "\n",
    "prompt 是一个 BasePromptTemplate，"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71d1ec233b581f92"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream')])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value = prompt.invoke({\"topic\": \"ice cream\"})\n",
    "prompt_value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T11:35:29.180Z",
     "start_time": "2023-12-26T11:35:29.141565Z"
    }
   },
   "id": "675fded5d9e69c93"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='tell me a short joke about ice cream')]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.to_messages()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:17:46.141632Z",
     "start_time": "2023-12-27T08:17:46.117744Z"
    }
   },
   "id": "f4c239370ed68282"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Human: tell me a short joke about ice cream'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value.to_string()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:18:22.849320Z",
     "start_time": "2023-12-27T08:18:22.742758Z"
    }
   },
   "id": "8d6c1b46b3739b03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44ff86e3716f7368"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"Why did the ice cream go to therapy?\\n\\nBecause it had too many toppings and couldn't cone-trol itself!\")"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = model.invoke(prompt_value)\n",
    "message"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:19:00.967865Z",
     "start_time": "2023-12-27T08:18:58.611529Z"
    }
   },
   "id": "772d214be7a5dda3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\nRobot: Why was the ice cream so sad? Because it was feeling a little rocky road!'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "llm.invoke(prompt_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:20:14.926173Z",
     "start_time": "2023-12-27T08:20:13.656934Z"
    }
   },
   "id": "437f140a2b2efe99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output parser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0a6b4fc6e2c0a6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Why did the ice cream go to therapy?\\n\\nBecause it had too many toppings and couldn't cone-trol itself!\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:20:47.871890Z",
     "start_time": "2023-12-27T08:20:47.811467Z"
    }
   },
   "id": "41094e9ee2ab8b0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entire Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "363e39da284a76d7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream')])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"topic\": \"ice cream\"}\n",
    "\n",
    "prompt.invoke(input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:21:56.043582Z",
     "start_time": "2023-12-27T08:21:55.981380Z"
    }
   },
   "id": "673f2bdb3720a60"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"Why did the ice cream go to therapy?\\n\\nBecause it had too many toppings and couldn't find its scoop-identity!\")"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | model).invoke(input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:22:25.965478Z",
     "start_time": "2023-12-27T08:22:18.376044Z"
    }
   },
   "id": "6f3dd6ddb598f378"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAG Search Example\n",
    "\n",
    "对于我们的下一个示例，我们希望运行检索增强生成链以在回答问题时添加一些上下文。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7035921131860b81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install langchain docarray tiktoken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d04d454560967bd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ValidationError: 2 validation errors for DocArrayDoc\n",
    "# https://github.com/langchain-ai/langchain/issues/14585\n",
    "\n",
    "!pip install --upgrade pydantic==1.10.13"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a449a4ccef225181"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'Harrison worked at Kensho.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires:\n",
    "# pip install langchain docarray tiktoken\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "chain.invoke(\"where did harrison work?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:58:46.854826Z",
     "start_time": "2023-12-27T08:58:43.956256Z"
    }
   },
   "id": "1a8c5d793515510e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "76e0683e53854932"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
